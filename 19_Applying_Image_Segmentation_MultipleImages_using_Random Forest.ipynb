{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Image Segmentation for multiple images using ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    " \n",
    "def feature_extraction(img):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "\n",
    "#All features generated must match the way features are generated for TRAINING.\n",
    "#Feature1 is our original image pixels\n",
    "    img2 = img.reshape(-1)\n",
    "    df['Original Image'] = img2\n",
    "\n",
    "#Generate Gabor features\n",
    "    num = 1\n",
    "    kernels = []\n",
    "    for theta in range(2):\n",
    "        theta = theta / 4. * np.pi\n",
    "        for sigma in (1, 3):\n",
    "            for lamda in np.arange(0, np.pi, np.pi / 4):\n",
    "                for gamma in (0.05, 0.5):\n",
    "#               print(theta, sigma, , lamda, frequency)\n",
    "                \n",
    "                    gabor_label = 'Gabor' + str(num)\n",
    "#                    print(gabor_label)\n",
    "                    ksize=9\n",
    "                    kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)    \n",
    "                    kernels.append(kernel)\n",
    "                    #Now filter image and add values to new column\n",
    "                    fimg = cv2.filter2D(img2, cv2.CV_8UC3, kernel)\n",
    "                    filtered_img = fimg.reshape(-1)\n",
    "                    df[gabor_label] = filtered_img  #Modify this to add new column for each gabor\n",
    "                    num += 1\n",
    "########################################\n",
    "#Geerate OTHER FEATURES and add them to the data frame\n",
    "#Feature 3 is canny edge\n",
    "    edges = cv2.Canny(img, 100,200)   #Image, min and max values\n",
    "    edges1 = edges.reshape(-1)\n",
    "    df['Canny Edge'] = edges1 #Add column to original dataframe\n",
    "\n",
    "    from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "\n",
    "#Feature 4 is Roberts edge\n",
    "    edge_roberts = roberts(img)\n",
    "    edge_roberts1 = edge_roberts.reshape(-1)\n",
    "    df['Roberts'] = edge_roberts1\n",
    "\n",
    "#Feature 5 is Sobel\n",
    "    edge_sobel = sobel(img)\n",
    "    edge_sobel1 = edge_sobel.reshape(-1)\n",
    "    df['Sobel'] = edge_sobel1\n",
    "\n",
    "#Feature 6 is Scharr\n",
    "    edge_scharr = scharr(img)\n",
    "    edge_scharr1 = edge_scharr.reshape(-1)\n",
    "    df['Scharr'] = edge_scharr1\n",
    "\n",
    "    #Feature 7 is Prewitt\n",
    "    edge_prewitt = prewitt(img)\n",
    "    edge_prewitt1 = edge_prewitt.reshape(-1)\n",
    "    df['Prewitt'] = edge_prewitt1\n",
    "\n",
    "    #Feature 8 is Gaussian with sigma=3\n",
    "    from scipy import ndimage as nd\n",
    "    gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "    gaussian_img1 = gaussian_img.reshape(-1)\n",
    "    df['Gaussian s3'] = gaussian_img1\n",
    "\n",
    "    #Feature 9 is Gaussian with sigma=7\n",
    "    gaussian_img2 = nd.gaussian_filter(img, sigma=7)\n",
    "    gaussian_img3 = gaussian_img2.reshape(-1)\n",
    "    df['Gaussian s7'] = gaussian_img3\n",
    "\n",
    "    #Feature 10 is Median with sigma=3\n",
    "    median_img = nd.median_filter(img, size=3)\n",
    "    median_img1 = median_img.reshape(-1)\n",
    "    df['Median s3'] = median_img1\n",
    "\n",
    "#     #Feature 11 is Variance with size=3\n",
    "#     variance_img = nd.generic_filter(img, np.var, size=3)\n",
    "#     variance_img1 = variance_img.reshape(-1)\n",
    "#     df['Variance s3'] = variance_img1  #Add column to original dataframe\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying trained model to segment multiple files. \n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "# from PIL import TiffImagePlugin   #for .tif key error\n",
    "\n",
    "filename = \"sandstone_model\"\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "path = \"images/Train_images/*.tif\"\n",
    "\n",
    "for file in glob.glob(path):\n",
    "#     print(file)     ##just stop here to see all file names printed\n",
    "    img1= cv2.imread(file)\n",
    "    img = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Call the feature extraction function.\n",
    "    X = feature_extraction(img)\n",
    "    result = loaded_model.predict(X)\n",
    "    segmented = result.reshape((img.shape))\n",
    "    \n",
    "    name = file.split(\".\")\n",
    "#     print(name[0])\n",
    "    plt.imsave(name[0]+\"_segmented.tiff\", segmented, cmap ='jet')\n",
    "\n",
    "#Above, we are splitting the file path into 2 -> creates a list with 2 entries\n",
    "#Then we are taking the second half of name to save segmented images with that name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
