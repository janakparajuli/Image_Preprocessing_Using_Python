{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grain Size Analysis for multiple images using Watershed Segmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watershed Segmentation Documentation:\n",
    "\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_watershed/py_watershed.html\n",
    "\n",
    "- This code performs grain size distribution analysis and dumps results into a csv file.\n",
    "- It uses watershed segmentation for better segmentation.\n",
    "- Compare results to regular segmentation. \n",
    "for multiple files.\n",
    "\n",
    "Better than for loops, just put all code into a function and apply the function to multiple images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import measure, color, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grain_segmentation(img):\n",
    "    \n",
    "#Threshold image to binary using OTSU. ALl thresholded pixels will be set to 255\n",
    "    ret1, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# Morphological operations to remove small noise - opening\n",
    "#To remove holes we can use closing\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 1)\n",
    "\n",
    "\n",
    "#Now we know that the regions at the center of cells is for sure cells\n",
    "#The region far away is background.\n",
    "#We need to extract sure regions. For that we can use erode. \n",
    "#But we have cells touching, so erode alone will not work. \n",
    "#To separate touching objects, the best approach would be distance transform and then thresholding.\n",
    "\n",
    "# let us start by identifying sure background area\n",
    "# dilating pixes a few times increases cell boundary to background. \n",
    "# This way whatever is remaining for sure will be background. \n",
    "#The area in between sure background and foreground is our ambiguous area. \n",
    "#Watershed should find this area for us. \n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=2)\n",
    "\n",
    "\n",
    "# Finding sure foreground area using distance transform and thresholding\n",
    "#intensities of the points inside the foreground regions are changed to \n",
    "#distance their respective distances from the closest 0 value (boundary).\n",
    "#https://www.tutorialspoint.com/opencv/opencv_distance_transformation.htm\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,3)\n",
    "\n",
    "\n",
    "#Let us threshold the dist transform by starting at 1/2 its max value.\n",
    "#print(dist_transform.max()) gives about 21.9\n",
    "    ret2, sure_fg = cv2.threshold(dist_transform,0.2*dist_transform.max(),255,0)\n",
    "\n",
    "#0.2* max value seems to separate the cells well.\n",
    "#High value like 0.5 will not recognize some grain boundaries.\n",
    "\n",
    "# Unknown ambiguous region is nothing but bkground - foreground\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "#Now we create a marker and label the regions inside. \n",
    "# For sure regions, both foreground and background will be labeled with positive numbers.\n",
    "# Unknown regions will be labeled 0. \n",
    "#For markers let us use ConnectedComponents. \n",
    "    ret3, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "#One problem rightnow is that the entire background pixels is given value 0.\n",
    "#This means watershed considers this region as unknown.\n",
    "#So let us add 1 to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+10\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "#plt.imshow(markers)   #Look at the 3 distinct regions.\n",
    "\n",
    "#Now we are ready for watershed filling. \n",
    "    markers = cv2.watershed(img1,markers)\n",
    "#The boundary region will be marked -1\n",
    "#https://docs.opencv.org/3.3.1/d7/d1b/group__imgproc__misc.html#ga3267243e4d3f95165d55a618c65ac6e1\n",
    "\n",
    "#Let us color boundaries in yellow. \n",
    "    img1[markers == -1] = [0,255,255]  \n",
    "\n",
    "#    img2 = color.label2rgb(markers, bg_label=0)\n",
    "\n",
    "    #cv2.imshow('Overlay on original image', img1)\n",
    "    #cv2.imshow('Colored Grains', img2)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "#Now, time to extract properties of detected cells\n",
    "# regionprops function in skimage measure module calculates useful parameters for each object.\n",
    "    regions = measure.regionprops(markers, intensity_image=img)\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/grains/grains3.jpg\n",
      "images/grains/grains2.jpg\n",
      "images/grains/grains1.jpg\n"
     ]
    }
   ],
   "source": [
    "#Main program\n",
    "pixels_to_um = 0.5 # 1 pixel = 500 nm (got this from the metadata of original image)   \n",
    "\n",
    "propList = ['Area',\n",
    "            'equivalent_diameter', #Added... verify if it works\n",
    "            'orientation', #Added, verify if it works. Angle btwn x-axis and major axis.\n",
    "            'MajorAxisLength',\n",
    "            'MinorAxisLength',\n",
    "            'Perimeter',\n",
    "            'MinIntensity',\n",
    "            'MeanIntensity',\n",
    "            'MaxIntensity']    \n",
    "    \n",
    "output_file = open('images/grains/image_measurements2.csv', 'w')\n",
    "output_file.write('FileName' + \",\" + 'Grain #'+ \",\" + \",\" + \",\".join(propList) + '\\n') \n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "path = \"images/grains/*.jpg\"\n",
    "for file in glob.glob(path):\n",
    "    print(file)     #just stop here to see all file names printed\n",
    "    img1= cv2.imread(file)\n",
    "    \n",
    "    img = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Call the grain segmentation function.\n",
    "    regions = grain_segmentation(img)\n",
    "\n",
    "    grain_number = 1\n",
    "    for region_props in regions:\n",
    "        output_file.write(file+\",\")\n",
    "        output_file.write(str(grain_number) + ',')\n",
    "    #output cluster properties to the excel file\n",
    " #       output_file.write(str(region_props['Label']))\n",
    "        for i,prop in enumerate(propList):\n",
    "            if(prop == 'Area'): \n",
    "                to_print = region_props[prop]*pixels_to_um**2   #Convert pixel square to um square\n",
    "            elif(prop == 'orientation'): \n",
    "                to_print = region_props[prop]*57.2958  #Convert to degrees from radians\n",
    "            elif(prop.find('Intensity') < 0):          # Any prop without Intensity in its name\n",
    "                to_print = region_props[prop]*pixels_to_um\n",
    "            else: \n",
    "                to_print = region_props[prop]     #Reamining props, basically the ones with Intensity in its name\n",
    "            output_file.write(',' + str(to_print))\n",
    "        output_file.write('\\n')\n",
    "        grain_number += 1\n",
    "\n",
    "output_file.close()   #Closes the file, otherwise it would be read only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
